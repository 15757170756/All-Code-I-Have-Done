{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ligh\n",
    "\"\"\"In this assignment, you should train your own net on cifar10 classification with deep learning framework MXNet.\n",
    "   With MXNet, you only need to define the nets with symbol connection, then set hyperparameters to train the \n",
    "   network. You can also save your model and load pretrained model to finetune the network. Make sure using GPU \n",
    "   mode. You should achieve at least 80% on the validation set.\"\"\"\n",
    "\n",
    "\"\"\"vist http://mxnet.io/get_started/index.html to get familar with mxnet!\"\"\"\n",
    "   \n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import logging\n",
    "\n",
    "# download data if necessary\n",
    "def _download(data_dir):\n",
    "    if not os.path.isdir(data_dir):\n",
    "        os.system(\"mkdir \" + data_dir)\n",
    "    os.chdir(data_dir)\n",
    "    if (not os.path.exists('train.rec')) or \\\n",
    "       (not os.path.exists('test.rec')) :\n",
    "        os.system(\"wget http://data.dmlc.ml/mxnet/data/cifar10.zip\")\n",
    "        os.system(\"unzip -u cifar10.zip\")\n",
    "        os.system(\"mv cifar/* .; rm -rf cifar; rm cifar10.zip\")\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "\n",
    "# data\n",
    "def get_iterator(data_shape=(3, 28, 28)):\n",
    "    if '://' not in data_dir:\n",
    "        _download(data_dir)\n",
    "\n",
    "    train = mx.io.ImageRecordIter(\n",
    "        path_imgrec = os.path.join(data_dir, \"train.rec\"),\n",
    "        mean_img    = os.path.join(data_dir, \"mean.bin\"),\n",
    "        data_shape  = data_shape,\n",
    "        batch_size  = batch_size,\n",
    "        rand_crop   = True,\n",
    "        rand_mirror = True)\n",
    "\n",
    "    val = mx.io.ImageRecordIter(\n",
    "        path_imgrec = os.path.join(data_dir, \"test.rec\"),\n",
    "        mean_img    = os.path.join(data_dir, \"mean.bin\"),\n",
    "        rand_crop   = False,\n",
    "        rand_mirror = False,\n",
    "        data_shape  = data_shape,\n",
    "        batch_size  = batch_size)\n",
    "\n",
    "    return (train, val)\n",
    "\n",
    "\n",
    "def get_net(num_classes=10):\n",
    "    #####################################################################################\n",
    "    # TODO: define your net                                                             #\n",
    "    # Define symbols that using convolution and max pooling to extract better features  #\n",
    "    # from input image.                                                                 #\n",
    "    #####################################################################################\n",
    "    data = mx.symbol.Variable(name=\"data\")\n",
    "    \n",
    "    conv1_1 = mx.symbol.Convolution(data=data, kernel=(3,3), pad=(1,1), num_filter=128, name=\"conv1_1\")\n",
    "    relu1_1 = mx.symbol.Activation(data=conv1_1, act_type=\"relu\", name=\"relu1_1\")\n",
    "    pool1 = mx.symbol.Pooling(data=relu1_1, pool_type=\"max\", kernel=(2,2), stride=(2,2), name=\"pool1\")\n",
    "    \n",
    "    conv2_1 = mx.symbol.Convolution(data=relu1_1, kernel=(3,3), pad=(1,1), num_filter=128, name=\"conv2_1\")\n",
    "    relu2_1 = mx.symbol.Activation(data=conv2_1, act_type=\"relu\", name=\"relu2_1\")\n",
    "    pool2 = mx.symbol.Pooling(data=relu2_1, pool_type=\"max\", kernel=(2,2), stride=(2,2), name=\"pool2\")\n",
    "    \n",
    "    conv3_1 = mx.symbol.Convolution(data=pool2, kernel=(5,5), pad=(2,2), num_filter=256, name=\"conv3_1\")\n",
    "    relu3_1 = mx.symbol.Activation(data=conv3_1, act_type=\"relu\", name=\"relu3_1\")\n",
    "    conv3_2 = mx.symbol.Convolution(data=relu3_1, kernel=(5,5), pad=(2,2), num_filter=256, name=\"conv3_2\")\n",
    "    relu3_2 = mx.symbol.Activation(data=conv3_2, act_type=\"relu\", name=\"relu3_2\")\n",
    "    pool_3 = mx.symbol.Pooling(data=relu3_2, pool_type=\"max\", kernel=(2,2), stride=(2,2), name=\"pool_3\")\n",
    "\n",
    "    flatten = mx.symbol.Flatten(data=pool_3, name=\"flatten\")\n",
    "    fc4 = mx.symbol.FullyConnected(data=flatten, num_hidden=1024, name=\"fc4\")\n",
    "    relu4 = mx.symbol.Activation(data=fc4, act_type=\"relu\", name=\"relu4\")\n",
    "    drop4 = mx.symbol.Dropout(data=relu4, p=0.5, name=\"drop4\")\n",
    "\n",
    "    fc5 = mx.symbol.FullyConnected(data=flatten, num_hidden=1024, name=\"fc5\")\n",
    "    relu5 = mx.symbol.Activation(data=fc5, act_type=\"relu\", name=\"relu5\")\n",
    "    drop5 = mx.symbol.Dropout(data=relu5, p=0.5, name=\"drop5\")\n",
    "\n",
    "    fc6 = mx.symbol.FullyConnected(data=drop5, num_hidden=1024, name=\"fc6\")\n",
    "    softmax = mx.symbol.SoftmaxOutput(data=fc6, name=\"softmax\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    #                              END OF YOUR CODE                                     #\n",
    "    #####################################################################################\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-30 21:19:22,299 Start training with [gpu(0)]\n",
      "2016-10-30 21:19:29,508 Epoch[0] Batch [50]\tSpeed: 1607.35 samples/sec\tTrain-accuracy=0.188281\n",
      "2016-10-30 21:19:33,601 Epoch[0] Batch [100]\tSpeed: 1565.07 samples/sec\tTrain-accuracy=0.310312\n",
      "2016-10-30 21:19:38,444 Epoch[0] Batch [150]\tSpeed: 1322.09 samples/sec\tTrain-accuracy=0.369219\n",
      "2016-10-30 21:19:44,035 Epoch[0] Batch [200]\tSpeed: 1145.76 samples/sec\tTrain-accuracy=0.393906\n",
      "2016-10-30 21:19:49,624 Epoch[0] Batch [250]\tSpeed: 1145.56 samples/sec\tTrain-accuracy=0.437344\n",
      "2016-10-30 21:19:54,429 Epoch[0] Batch [300]\tSpeed: 1332.45 samples/sec\tTrain-accuracy=0.444375\n",
      "2016-10-30 21:19:58,974 Epoch[0] Batch [350]\tSpeed: 1408.85 samples/sec\tTrain-accuracy=0.456719\n",
      "2016-10-30 21:20:03,090 Epoch[0] Resetting Data Iterator\n",
      "2016-10-30 21:20:03,092 Epoch[0] Time cost=38.937\n",
      "2016-10-30 21:20:06,773 Epoch[0] Validation-accuracy=0.524624\n",
      "2016-10-30 21:20:11,688 Epoch[1] Batch [50]\tSpeed: 1311.02 samples/sec\tTrain-accuracy=0.479531\n",
      "2016-10-30 21:20:16,605 Epoch[1] Batch [100]\tSpeed: 1301.84 samples/sec\tTrain-accuracy=0.501094\n",
      "2016-10-30 21:20:21,586 Epoch[1] Batch [150]\tSpeed: 1285.16 samples/sec\tTrain-accuracy=0.517500\n",
      "2016-10-30 21:20:26,515 Epoch[1] Batch [200]\tSpeed: 1298.93 samples/sec\tTrain-accuracy=0.527344\n",
      "2016-10-30 21:20:31,508 Epoch[1] Batch [250]\tSpeed: 1282.09 samples/sec\tTrain-accuracy=0.540625\n",
      "2016-10-30 21:20:36,295 Epoch[1] Batch [300]\tSpeed: 1337.47 samples/sec\tTrain-accuracy=0.540937\n",
      "2016-10-30 21:20:40,756 Epoch[1] Batch [350]\tSpeed: 1435.60 samples/sec\tTrain-accuracy=0.547344\n",
      "2016-10-30 21:20:44,407 Epoch[1] Resetting Data Iterator\n",
      "2016-10-30 21:20:44,409 Epoch[1] Time cost=37.634\n",
      "2016-10-30 21:20:47,371 Epoch[1] Validation-accuracy=0.624703\n",
      "2016-10-30 21:20:52,132 Epoch[2] Batch [50]\tSpeed: 1361.62 samples/sec\tTrain-accuracy=0.566094\n",
      "2016-10-30 21:20:57,132 Epoch[2] Batch [100]\tSpeed: 1280.38 samples/sec\tTrain-accuracy=0.587656\n",
      "2016-10-30 21:21:01,645 Epoch[2] Batch [150]\tSpeed: 1419.20 samples/sec\tTrain-accuracy=0.595469\n",
      "2016-10-30 21:21:06,250 Epoch[2] Batch [200]\tSpeed: 1390.39 samples/sec\tTrain-accuracy=0.596250\n",
      "2016-10-30 21:21:12,909 Epoch[2] Batch [250]\tSpeed: 961.41 samples/sec\tTrain-accuracy=0.614844\n",
      "2016-10-30 21:21:19,585 Epoch[2] Batch [300]\tSpeed: 958.84 samples/sec\tTrain-accuracy=0.603125\n",
      "2016-10-30 21:21:26,284 Epoch[2] Batch [350]\tSpeed: 955.59 samples/sec\tTrain-accuracy=0.609375\n",
      "2016-10-30 21:21:31,502 Epoch[2] Resetting Data Iterator\n",
      "2016-10-30 21:21:31,505 Epoch[2] Time cost=44.131\n",
      "2016-10-30 21:21:35,936 Epoch[2] Validation-accuracy=0.655261\n",
      "2016-10-30 21:21:42,288 Epoch[3] Batch [50]\tSpeed: 1014.52 samples/sec\tTrain-accuracy=0.626406\n",
      "2016-10-30 21:21:48,708 Epoch[3] Batch [100]\tSpeed: 997.31 samples/sec\tTrain-accuracy=0.632656\n",
      "2016-10-30 21:21:55,353 Epoch[3] Batch [150]\tSpeed: 963.36 samples/sec\tTrain-accuracy=0.656406\n",
      "2016-10-30 21:22:01,970 Epoch[3] Batch [200]\tSpeed: 967.43 samples/sec\tTrain-accuracy=0.643281\n",
      "2016-10-30 21:22:08,574 Epoch[3] Batch [250]\tSpeed: 969.35 samples/sec\tTrain-accuracy=0.654687\n",
      "2016-10-30 21:22:15,259 Epoch[3] Batch [300]\tSpeed: 957.58 samples/sec\tTrain-accuracy=0.653906\n",
      "2016-10-30 21:22:21,818 Epoch[3] Batch [350]\tSpeed: 975.92 samples/sec\tTrain-accuracy=0.660312\n",
      "2016-10-30 21:22:27,169 Epoch[3] Resetting Data Iterator\n",
      "2016-10-30 21:22:27,170 Epoch[3] Time cost=51.233\n",
      "2016-10-30 21:22:30,692 Epoch[3] Validation-accuracy=0.706388\n",
      "2016-10-30 21:22:37,275 Epoch[4] Batch [50]\tSpeed: 986.99 samples/sec\tTrain-accuracy=0.660625\n",
      "2016-10-30 21:22:43,914 Epoch[4] Batch [100]\tSpeed: 964.31 samples/sec\tTrain-accuracy=0.677969\n",
      "2016-10-30 21:22:50,534 Epoch[4] Batch [150]\tSpeed: 967.02 samples/sec\tTrain-accuracy=0.677031\n",
      "2016-10-30 21:22:57,217 Epoch[4] Batch [200]\tSpeed: 957.82 samples/sec\tTrain-accuracy=0.687500\n",
      "2016-10-30 21:23:03,874 Epoch[4] Batch [250]\tSpeed: 961.65 samples/sec\tTrain-accuracy=0.687344\n",
      "2016-10-30 21:23:10,566 Epoch[4] Batch [300]\tSpeed: 956.58 samples/sec\tTrain-accuracy=0.678125\n",
      "2016-10-30 21:23:17,302 Epoch[4] Batch [350]\tSpeed: 950.28 samples/sec\tTrain-accuracy=0.687813\n",
      "2016-10-30 21:23:22,807 Epoch[4] Resetting Data Iterator\n",
      "2016-10-30 21:23:22,808 Epoch[4] Time cost=52.115\n",
      "2016-10-30 21:23:26,416 Epoch[4] Validation-accuracy=0.714201\n",
      "2016-10-30 21:23:33,100 Epoch[5] Batch [50]\tSpeed: 964.70 samples/sec\tTrain-accuracy=0.689688\n",
      "2016-10-30 21:23:39,852 Epoch[5] Batch [100]\tSpeed: 948.11 samples/sec\tTrain-accuracy=0.690937\n",
      "2016-10-30 21:23:46,596 Epoch[5] Batch [150]\tSpeed: 949.36 samples/sec\tTrain-accuracy=0.701875\n",
      "2016-10-30 21:23:53,337 Epoch[5] Batch [200]\tSpeed: 949.70 samples/sec\tTrain-accuracy=0.712344\n",
      "2016-10-30 21:24:00,039 Epoch[5] Batch [250]\tSpeed: 955.19 samples/sec\tTrain-accuracy=0.696562\n",
      "2016-10-30 21:24:06,757 Epoch[5] Batch [300]\tSpeed: 953.18 samples/sec\tTrain-accuracy=0.703125\n",
      "2016-10-30 21:24:13,480 Epoch[5] Batch [350]\tSpeed: 952.05 samples/sec\tTrain-accuracy=0.707500\n",
      "2016-10-30 21:24:18,834 Epoch[5] Resetting Data Iterator\n",
      "2016-10-30 21:24:18,835 Epoch[5] Time cost=52.417\n",
      "2016-10-30 21:24:22,557 Epoch[5] Validation-accuracy=0.735166\n",
      "2016-10-30 21:24:29,085 Epoch[6] Batch [50]\tSpeed: 987.25 samples/sec\tTrain-accuracy=0.715781\n",
      "2016-10-30 21:24:35,723 Epoch[6] Batch [100]\tSpeed: 964.35 samples/sec\tTrain-accuracy=0.722031\n",
      "2016-10-30 21:24:41,713 Epoch[6] Batch [150]\tSpeed: 1068.72 samples/sec\tTrain-accuracy=0.728281\n",
      "2016-10-30 21:24:46,159 Epoch[6] Batch [200]\tSpeed: 1440.02 samples/sec\tTrain-accuracy=0.737812\n",
      "2016-10-30 21:24:50,614 Epoch[6] Batch [250]\tSpeed: 1436.91 samples/sec\tTrain-accuracy=0.721719\n",
      "2016-10-30 21:24:55,057 Epoch[6] Batch [300]\tSpeed: 1440.97 samples/sec\tTrain-accuracy=0.721094\n",
      "2016-10-30 21:24:59,509 Epoch[6] Batch [350]\tSpeed: 1438.24 samples/sec\tTrain-accuracy=0.731250\n",
      "2016-10-30 21:25:03,160 Epoch[6] Resetting Data Iterator\n",
      "2016-10-30 21:25:03,174 Epoch[6] Time cost=40.616\n",
      "2016-10-30 21:25:06,345 Epoch[6] Validation-accuracy=0.751286\n",
      "2016-10-30 21:25:10,761 Epoch[7] Batch [50]\tSpeed: 1468.73 samples/sec\tTrain-accuracy=0.740469\n",
      "2016-10-30 21:25:15,223 Epoch[7] Batch [100]\tSpeed: 1434.68 samples/sec\tTrain-accuracy=0.745313\n",
      "2016-10-30 21:25:19,668 Epoch[7] Batch [150]\tSpeed: 1441.35 samples/sec\tTrain-accuracy=0.746250\n",
      "2016-10-30 21:25:24,119 Epoch[7] Batch [200]\tSpeed: 1438.53 samples/sec\tTrain-accuracy=0.752656\n",
      "2016-10-30 21:25:28,575 Epoch[7] Batch [250]\tSpeed: 1436.61 samples/sec\tTrain-accuracy=0.749062\n",
      "2016-10-30 21:25:33,033 Epoch[7] Batch [300]\tSpeed: 1435.97 samples/sec\tTrain-accuracy=0.746875\n",
      "2016-10-30 21:25:37,503 Epoch[7] Batch [350]\tSpeed: 1432.33 samples/sec\tTrain-accuracy=0.748437\n",
      "2016-10-30 21:25:41,080 Epoch[7] Resetting Data Iterator\n",
      "2016-10-30 21:25:41,097 Epoch[7] Time cost=34.751\n",
      "2016-10-30 21:25:44,371 Epoch[7] Validation-accuracy=0.761768\n",
      "2016-10-30 21:25:48,792 Epoch[8] Batch [50]\tSpeed: 1467.32 samples/sec\tTrain-accuracy=0.749062\n",
      "2016-10-30 21:25:53,251 Epoch[8] Batch [100]\tSpeed: 1435.58 samples/sec\tTrain-accuracy=0.755781\n",
      "2016-10-30 21:25:57,708 Epoch[8] Batch [150]\tSpeed: 1436.43 samples/sec\tTrain-accuracy=0.765156\n",
      "2016-10-30 21:26:02,167 Epoch[8] Batch [200]\tSpeed: 1435.54 samples/sec\tTrain-accuracy=0.760312\n",
      "2016-10-30 21:26:06,635 Epoch[8] Batch [250]\tSpeed: 1432.98 samples/sec\tTrain-accuracy=0.752500\n",
      "2016-10-30 21:26:11,099 Epoch[8] Batch [300]\tSpeed: 1434.53 samples/sec\tTrain-accuracy=0.759219\n",
      "2016-10-30 21:26:15,552 Epoch[8] Batch [350]\tSpeed: 1437.64 samples/sec\tTrain-accuracy=0.761563\n",
      "2016-10-30 21:26:19,205 Epoch[8] Resetting Data Iterator\n",
      "2016-10-30 21:26:19,206 Epoch[8] Time cost=34.834\n",
      "2016-10-30 21:26:22,245 Epoch[8] Validation-accuracy=0.772646\n",
      "2016-10-30 21:26:26,682 Epoch[9] Batch [50]\tSpeed: 1462.56 samples/sec\tTrain-accuracy=0.767031\n",
      "2016-10-30 21:26:31,129 Epoch[9] Batch [100]\tSpeed: 1439.66 samples/sec\tTrain-accuracy=0.774531\n",
      "2016-10-30 21:26:35,576 Epoch[9] Batch [150]\tSpeed: 1439.61 samples/sec\tTrain-accuracy=0.777188\n",
      "2016-10-30 21:26:40,035 Epoch[9] Batch [200]\tSpeed: 1435.72 samples/sec\tTrain-accuracy=0.764531\n",
      "2016-10-30 21:26:44,493 Epoch[9] Batch [250]\tSpeed: 1435.87 samples/sec\tTrain-accuracy=0.771875\n",
      "2016-10-30 21:26:48,942 Epoch[9] Batch [300]\tSpeed: 1439.34 samples/sec\tTrain-accuracy=0.770000\n",
      "2016-10-30 21:26:53,396 Epoch[9] Batch [350]\tSpeed: 1437.25 samples/sec\tTrain-accuracy=0.776563\n",
      "2016-10-30 21:26:57,046 Epoch[9] Resetting Data Iterator\n",
      "2016-10-30 21:26:57,047 Epoch[9] Time cost=34.800\n",
      "2016-10-30 21:26:58,366 Saved checkpoint to \"model/net1-0010.params\"\n",
      "2016-10-30 21:27:00,658 Epoch[9] Validation-accuracy=0.774921\n",
      "2016-10-30 21:27:05,074 Epoch[10] Batch [50]\tSpeed: 1468.74 samples/sec\tTrain-accuracy=0.782813\n",
      "2016-10-30 21:27:10,565 Epoch[10] Batch [100]\tSpeed: 1165.74 samples/sec\tTrain-accuracy=0.777500\n",
      "2016-10-30 21:27:17,289 Epoch[10] Batch [150]\tSpeed: 952.07 samples/sec\tTrain-accuracy=0.787031\n",
      "2016-10-30 21:27:24,009 Epoch[10] Batch [200]\tSpeed: 952.71 samples/sec\tTrain-accuracy=0.788750\n",
      "2016-10-30 21:27:30,495 Epoch[10] Batch [250]\tSpeed: 986.94 samples/sec\tTrain-accuracy=0.774375\n",
      "2016-10-30 21:27:37,026 Epoch[10] Batch [300]\tSpeed: 980.06 samples/sec\tTrain-accuracy=0.780781\n",
      "2016-10-30 21:27:43,561 Epoch[10] Batch [350]\tSpeed: 979.69 samples/sec\tTrain-accuracy=0.793750\n",
      "2016-10-30 21:27:48,802 Epoch[10] Resetting Data Iterator\n",
      "2016-10-30 21:27:48,803 Epoch[10] Time cost=48.144\n",
      "2016-10-30 21:27:53,215 Epoch[10] Validation-accuracy=0.788370\n",
      "2016-10-30 21:27:59,600 Epoch[11] Batch [50]\tSpeed: 1009.27 samples/sec\tTrain-accuracy=0.786094\n",
      "2016-10-30 21:28:06,098 Epoch[11] Batch [100]\tSpeed: 985.30 samples/sec\tTrain-accuracy=0.798281\n",
      "2016-10-30 21:28:12,687 Epoch[11] Batch [150]\tSpeed: 971.48 samples/sec\tTrain-accuracy=0.803750\n",
      "2016-10-30 21:28:19,280 Epoch[11] Batch [200]\tSpeed: 970.88 samples/sec\tTrain-accuracy=0.797188\n",
      "2016-10-30 21:28:25,904 Epoch[11] Batch [250]\tSpeed: 966.45 samples/sec\tTrain-accuracy=0.788750\n",
      "2016-10-30 21:28:32,476 Epoch[11] Batch [300]\tSpeed: 974.05 samples/sec\tTrain-accuracy=0.789375\n",
      "2016-10-30 21:28:39,079 Epoch[11] Batch [350]\tSpeed: 969.45 samples/sec\tTrain-accuracy=0.794844\n",
      "2016-10-30 21:28:44,529 Epoch[11] Resetting Data Iterator\n",
      "2016-10-30 21:28:44,531 Epoch[11] Time cost=51.315\n",
      "2016-10-30 21:28:48,987 Epoch[11] Validation-accuracy=0.795787\n",
      "2016-10-30 21:28:55,415 Epoch[12] Batch [50]\tSpeed: 1003.03 samples/sec\tTrain-accuracy=0.794844\n",
      "2016-10-30 21:29:01,913 Epoch[12] Batch [100]\tSpeed: 985.18 samples/sec\tTrain-accuracy=0.801562\n",
      "2016-10-30 21:29:08,486 Epoch[12] Batch [150]\tSpeed: 973.82 samples/sec\tTrain-accuracy=0.808125\n",
      "2016-10-30 21:29:15,105 Epoch[12] Batch [200]\tSpeed: 967.02 samples/sec\tTrain-accuracy=0.805156\n",
      "2016-10-30 21:29:21,731 Epoch[12] Batch [250]\tSpeed: 966.10 samples/sec\tTrain-accuracy=0.802031\n",
      "2016-10-30 21:29:28,351 Epoch[12] Batch [300]\tSpeed: 966.93 samples/sec\tTrain-accuracy=0.796719\n",
      "2016-10-30 21:29:34,984 Epoch[12] Batch [350]\tSpeed: 965.16 samples/sec\tTrain-accuracy=0.805156\n",
      "2016-10-30 21:29:40,450 Epoch[12] Resetting Data Iterator\n",
      "2016-10-30 21:29:40,451 Epoch[12] Time cost=51.463\n",
      "2016-10-30 21:29:44,637 Epoch[12] Validation-accuracy=0.800831\n",
      "2016-10-30 21:29:51,062 Epoch[13] Batch [50]\tSpeed: 1003.39 samples/sec\tTrain-accuracy=0.806875\n",
      "2016-10-30 21:29:57,603 Epoch[13] Batch [100]\tSpeed: 978.61 samples/sec\tTrain-accuracy=0.804531\n",
      "2016-10-30 21:30:04,160 Epoch[13] Batch [150]\tSpeed: 976.30 samples/sec\tTrain-accuracy=0.809219\n",
      "2016-10-30 21:30:11,237 Epoch[13] Batch [200]\tSpeed: 904.52 samples/sec\tTrain-accuracy=0.807187\n",
      "2016-10-30 21:30:19,038 Epoch[13] Batch [250]\tSpeed: 820.79 samples/sec\tTrain-accuracy=0.805156\n",
      "2016-10-30 21:30:26,621 Epoch[13] Batch [300]\tSpeed: 844.14 samples/sec\tTrain-accuracy=0.807344\n",
      "2016-10-30 21:30:34,168 Epoch[13] Batch [350]\tSpeed: 848.18 samples/sec\tTrain-accuracy=0.817031\n",
      "2016-10-30 21:30:40,072 Epoch[13] Resetting Data Iterator\n",
      "2016-10-30 21:30:40,082 Epoch[13] Time cost=55.444\n",
      "2016-10-30 21:30:42,978 Epoch[13] Validation-accuracy=0.811511\n",
      "2016-10-30 21:30:47,375 Epoch[14] Batch [50]\tSpeed: 1475.51 samples/sec\tTrain-accuracy=0.819844\n",
      "2016-10-30 21:30:51,834 Epoch[14] Batch [100]\tSpeed: 1435.68 samples/sec\tTrain-accuracy=0.820156\n",
      "2016-10-30 21:30:56,300 Epoch[14] Batch [150]\tSpeed: 1433.84 samples/sec\tTrain-accuracy=0.816562\n",
      "2016-10-30 21:31:00,758 Epoch[14] Batch [200]\tSpeed: 1436.27 samples/sec\tTrain-accuracy=0.823438\n",
      "2016-10-30 21:31:05,210 Epoch[14] Batch [250]\tSpeed: 1437.99 samples/sec\tTrain-accuracy=0.817031\n",
      "2016-10-30 21:31:09,669 Epoch[14] Batch [300]\tSpeed: 1435.48 samples/sec\tTrain-accuracy=0.816094\n",
      "2016-10-30 21:31:14,120 Epoch[14] Batch [350]\tSpeed: 1438.67 samples/sec\tTrain-accuracy=0.822344\n",
      "2016-10-30 21:31:17,814 Epoch[14] Resetting Data Iterator\n",
      "2016-10-30 21:31:17,815 Epoch[14] Time cost=34.836\n",
      "2016-10-30 21:31:21,388 Epoch[14] Validation-accuracy=0.807555\n",
      "2016-10-30 21:31:27,551 Epoch[15] Batch [50]\tSpeed: 1046.22 samples/sec\tTrain-accuracy=0.821719\n",
      "2016-10-30 21:31:33,790 Epoch[15] Batch [100]\tSpeed: 1025.98 samples/sec\tTrain-accuracy=0.819531\n",
      "2016-10-30 21:31:40,030 Epoch[15] Batch [150]\tSpeed: 1026.02 samples/sec\tTrain-accuracy=0.819375\n",
      "2016-10-30 21:31:46,095 Epoch[15] Batch [200]\tSpeed: 1055.66 samples/sec\tTrain-accuracy=0.828438\n",
      "2016-10-30 21:31:52,326 Epoch[15] Batch [250]\tSpeed: 1027.36 samples/sec\tTrain-accuracy=0.827187\n",
      "2016-10-30 21:31:58,563 Epoch[15] Batch [300]\tSpeed: 1026.45 samples/sec\tTrain-accuracy=0.822031\n",
      "2016-10-30 21:32:04,769 Epoch[15] Batch [350]\tSpeed: 1031.69 samples/sec\tTrain-accuracy=0.831875\n",
      "2016-10-30 21:32:09,750 Epoch[15] Resetting Data Iterator\n",
      "2016-10-30 21:32:09,752 Epoch[15] Time cost=48.363\n",
      "2016-10-30 21:32:13,420 Epoch[15] Validation-accuracy=0.817840\n",
      "2016-10-30 21:32:19,517 Epoch[16] Batch [50]\tSpeed: 1056.97 samples/sec\tTrain-accuracy=0.832031\n",
      "2016-10-30 21:32:25,662 Epoch[16] Batch [100]\tSpeed: 1041.89 samples/sec\tTrain-accuracy=0.825313\n",
      "2016-10-30 21:32:30,149 Epoch[16] Batch [150]\tSpeed: 1426.75 samples/sec\tTrain-accuracy=0.840469\n",
      "2016-10-30 21:32:34,616 Epoch[16] Batch [200]\tSpeed: 1433.15 samples/sec\tTrain-accuracy=0.834688\n",
      "2016-10-30 21:32:39,073 Epoch[16] Batch [250]\tSpeed: 1436.37 samples/sec\tTrain-accuracy=0.828125\n",
      "2016-10-30 21:32:43,523 Epoch[16] Batch [300]\tSpeed: 1438.92 samples/sec\tTrain-accuracy=0.830313\n",
      "2016-10-30 21:32:47,988 Epoch[16] Batch [350]\tSpeed: 1433.96 samples/sec\tTrain-accuracy=0.834531\n",
      "2016-10-30 21:32:51,644 Epoch[16] Resetting Data Iterator\n",
      "2016-10-30 21:32:51,646 Epoch[16] Time cost=38.225\n",
      "2016-10-30 21:32:54,546 Epoch[16] Validation-accuracy=0.819917\n",
      "2016-10-30 21:32:58,965 Epoch[17] Batch [50]\tSpeed: 1467.84 samples/sec\tTrain-accuracy=0.840313\n",
      "2016-10-30 21:33:03,443 Epoch[17] Batch [100]\tSpeed: 1429.51 samples/sec\tTrain-accuracy=0.845156\n",
      "2016-10-30 21:33:07,878 Epoch[17] Batch [150]\tSpeed: 1444.67 samples/sec\tTrain-accuracy=0.840625\n",
      "2016-10-30 21:33:12,324 Epoch[17] Batch [200]\tSpeed: 1439.72 samples/sec\tTrain-accuracy=0.837969\n",
      "2016-10-30 21:33:16,782 Epoch[17] Batch [250]\tSpeed: 1435.94 samples/sec\tTrain-accuracy=0.830156\n",
      "2016-10-30 21:33:21,238 Epoch[17] Batch [300]\tSpeed: 1437.05 samples/sec\tTrain-accuracy=0.841094\n",
      "2016-10-30 21:33:25,682 Epoch[17] Batch [350]\tSpeed: 1440.27 samples/sec\tTrain-accuracy=0.840156\n",
      "2016-10-30 21:33:29,336 Epoch[17] Resetting Data Iterator\n",
      "2016-10-30 21:33:29,337 Epoch[17] Time cost=34.790\n",
      "2016-10-30 21:33:32,319 Epoch[17] Validation-accuracy=0.815665\n",
      "2016-10-30 21:33:36,741 Epoch[18] Batch [50]\tSpeed: 1467.18 samples/sec\tTrain-accuracy=0.836875\n",
      "2016-10-30 21:33:41,187 Epoch[18] Batch [100]\tSpeed: 1440.08 samples/sec\tTrain-accuracy=0.841719\n",
      "2016-10-30 21:33:45,635 Epoch[18] Batch [150]\tSpeed: 1439.35 samples/sec\tTrain-accuracy=0.852031\n",
      "2016-10-30 21:33:50,093 Epoch[18] Batch [200]\tSpeed: 1435.96 samples/sec\tTrain-accuracy=0.847656\n",
      "2016-10-30 21:33:54,540 Epoch[18] Batch [250]\tSpeed: 1439.65 samples/sec\tTrain-accuracy=0.843906\n",
      "2016-10-30 21:33:58,988 Epoch[18] Batch [300]\tSpeed: 1439.19 samples/sec\tTrain-accuracy=0.846094\n",
      "2016-10-30 21:34:03,439 Epoch[18] Batch [350]\tSpeed: 1438.09 samples/sec\tTrain-accuracy=0.837031\n",
      "2016-10-30 21:34:07,003 Epoch[18] Resetting Data Iterator\n",
      "2016-10-30 21:34:07,008 Epoch[18] Time cost=34.687\n",
      "2016-10-30 21:34:09,951 Epoch[18] Validation-accuracy=0.823279\n",
      "2016-10-30 21:34:14,368 Epoch[19] Batch [50]\tSpeed: 1468.09 samples/sec\tTrain-accuracy=0.852344\n",
      "2016-10-30 21:34:18,826 Epoch[19] Batch [100]\tSpeed: 1436.59 samples/sec\tTrain-accuracy=0.850156\n",
      "2016-10-30 21:34:23,276 Epoch[19] Batch [150]\tSpeed: 1438.77 samples/sec\tTrain-accuracy=0.857031\n",
      "2016-10-30 21:34:27,729 Epoch[19] Batch [200]\tSpeed: 1437.61 samples/sec\tTrain-accuracy=0.846719\n",
      "2016-10-30 21:34:32,189 Epoch[19] Batch [250]\tSpeed: 1435.48 samples/sec\tTrain-accuracy=0.850938\n",
      "2016-10-30 21:34:36,646 Epoch[19] Batch [300]\tSpeed: 1436.50 samples/sec\tTrain-accuracy=0.852344\n",
      "2016-10-30 21:34:41,095 Epoch[19] Batch [350]\tSpeed: 1438.81 samples/sec\tTrain-accuracy=0.855313\n",
      "2016-10-30 21:34:44,754 Epoch[19] Resetting Data Iterator\n",
      "2016-10-30 21:34:44,758 Epoch[19] Time cost=34.807\n",
      "2016-10-30 21:34:45,548 Saved checkpoint to \"model/net1-0020.params\"\n",
      "2016-10-30 21:34:47,798 Epoch[19] Validation-accuracy=0.814181\n"
     ]
    }
   ],
   "source": [
    "network = get_net()\n",
    "\n",
    "################################################################################\n",
    "# TODO: this is similar as solver                                              #\n",
    "################################################################################\n",
    "\n",
    "############################ set hyperparameters ###############################\n",
    "batch_size = 128\n",
    "weight_decay =  1e-3\n",
    "num_epoch = 20\n",
    "learning_rate = 1e-4\n",
    "devs=mx.gpu(0)     # set device id\n",
    "\n",
    "################################  path #########################################\n",
    "data_dir = 'cifar10/'\n",
    "chk_dir = 'model/'\n",
    "chk_prefix = chk_dir +'net1'\n",
    "load_model = True   ## set true if you want to load a pretrained model and finetune with lower learning rate\n",
    "\n",
    "if not os.path.isdir(chk_dir):\n",
    "     os.system(\"mkdir \" + chk_dir)\n",
    "\n",
    "reload(logging)\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "eval_metrics = ['accuracy']\n",
    "\n",
    "## TopKAccuracy only allows top_k > 1\n",
    "#eval_metrics.append(mx.metric.create('top_k_accuracy', top_k = 5))\n",
    "\n",
    "if load_model:\n",
    "    model_prefix = 'model/net1'\n",
    "    model_iter = 20  # which model to load\n",
    "\n",
    "    _, arg_params,__ = mx.model.load_checkpoint(model_prefix, model_iter)\n",
    "else:\n",
    "    arg_params = None\n",
    "    model_iter = 0\n",
    "\n",
    "model=mx.model.FeedForward(\n",
    "       ctx      = devs,\n",
    "       symbol   = network,\n",
    "       arg_params = arg_params,\n",
    "       begin_epoch = model_iter,\n",
    "       num_epoch  = num_epoch,\n",
    "       learning_rate = learning_rate,\n",
    "       momentum      = 0.9,\n",
    "       wd            = weight_decay,\n",
    "      initializer   = mx.init.Xavier(factor_type='in', magnitude=2.34)    ## weight initialization\n",
    "       )\n",
    "\n",
    "train_ite, val_ite = get_iterator()\n",
    "model.fit(\n",
    "        X          = train_ite,\n",
    "        eval_data  = val_ite,\n",
    "        eval_metric = eval_metrics,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 50), \n",
    "        epoch_end_callback=mx.callback.do_checkpoint(chk_prefix, 10)   ## save your model after each 10 epochs\n",
    "        )\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
